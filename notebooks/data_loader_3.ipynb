{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13839323,"sourceType":"datasetVersion","datasetId":8814255}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:44:48.646327Z","iopub.execute_input":"2025-11-23T14:44:48.646704Z","iopub.status.idle":"2025-11-23T14:44:48.651914Z","shell.execute_reply.started":"2025-11-23T14:44:48.646677Z","shell.execute_reply":"2025-11-23T14:44:48.650905Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"class SignLanguageDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n\n        self.samples = []\n        self.classes = sorted(os.listdir(root_dir))\n        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n\n        for cls in self.classes:\n            cls_path = os.path.join(root_dir, cls)\n            for img_name in os.listdir(cls_path):\n                self.samples.append((os.path.join(cls_path, img_name), self.class_to_idx[cls]))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        img = Image.open(img_path).convert(\"RGB\")  # hoặc L nếu grayscale\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:40:20.801301Z","iopub.execute_input":"2025-11-23T14:40:20.801812Z","iopub.status.idle":"2025-11-23T14:40:20.809847Z","shell.execute_reply.started":"2025-11-23T14:40:20.801783Z","shell.execute_reply":"2025-11-23T14:40:20.808340Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"train_transform = T.Compose([\n    T.Resize((224, 224)),\n    T.RandomHorizontalFlip(p=0.5),        # flip ngang\n    T.RandomRotation(degrees=15),         # xoay nhẹ\n    T.ToTensor(),\n])\n\nval_transform = T.Compose([\n    T.Resize((224, 224)),\n    T.ToTensor(),\n])\n\ntest_transform = T.Compose([\n    T.Resize((224, 224)),\n    T.ToTensor(),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:44:23.722492Z","iopub.execute_input":"2025-11-23T14:44:23.722867Z","iopub.status.idle":"2025-11-23T14:44:23.730015Z","shell.execute_reply.started":"2025-11-23T14:44:23.722839Z","shell.execute_reply":"2025-11-23T14:44:23.728603Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"train_dir = \"/kaggle/working/vsl_split/train\"\nval_dir   = \"/kaggle/working/vsl_split/valid\"\ntest_dir  = \"/kaggle/working/vsl_split/test\"\n\ntrain_ds = SignLanguageDataset(train_dir, transform=train_transform)\nval_ds   = SignLanguageDataset(val_dir, transform=val_transform)\ntest_ds  = SignLanguageDataset(test_dir, transform=test_transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\ntest_loader  = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:45:33.123097Z","iopub.execute_input":"2025-11-23T14:45:33.123566Z","iopub.status.idle":"2025-11-23T14:45:33.157994Z","shell.execute_reply.started":"2025-11-23T14:45:33.123539Z","shell.execute_reply":"2025-11-23T14:45:33.156701Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"imgs, labels = next(iter(train_loader))\nprint(imgs.shape, labels[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:45:44.389601Z","iopub.execute_input":"2025-11-23T14:45:44.389975Z","iopub.status.idle":"2025-11-23T14:45:44.797639Z","shell.execute_reply.started":"2025-11-23T14:45:44.389948Z","shell.execute_reply":"2025-11-23T14:45:44.796497Z"}},"outputs":[{"name":"stdout","text":"torch.Size([32, 3, 224, 224]) tensor([ 2,  4,  7,  7,  8,  8, 21,  5, 21, 10])\n","output_type":"stream"}],"execution_count":29}]}